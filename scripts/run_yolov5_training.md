# YOLOv5 Training Guide – Lamb Activity Detection

This document describes how we trained the YOLOv5 models used in our ICCCNT 2024 experiments for lamb activity detection.

## 1. Clone YOLOv5 and install dependencies

From the repository root:

```bash
git clone https://github.com/ultralytics/yolov5.git
cd yolov5
pip install -r requirements.txt
```
We assume Python, PyTorch, and GPU drivers are already set up on the machine.

# 2. Check dataset configuration

Our YOLO dataset configuration is defined in:
```bash
config/yolo_dataset.yaml
```
It points to the split files generated by:

data/splits/train.txt

data/splits/val.txt

data/splits/test.txt

and uses 3 classes:

standing

eating

laying

Make sure the images and labels are prepared as described in the main README:

Images: data/images/

YOLO labels: data/labels_yolo/

3. Train YOLOv5

From inside the yolov5 folder:
```bash
python train.py \
  --img 640 \
  --batch 16 \
  --epochs 100 \
  --data ../config/yolo_dataset.yaml \
  --weights yolov5s.pt \
  --project ../runs_yolov5 \
  --name lamb_activity_yolov5s
```
Key points:

--img 640 matches the 640×480 image resolution we used in our experiments.

--data points to our dataset config file in the parent repo.

The run outputs (weights, logs, metrics) are stored in ../runs_yolov5/lamb_activity_yolov5s.

4. Export detections for evaluation and tracking

After training, we generate detections on the test set and store them in a CSV compatible with our evaluation and tracking scripts.

From inside yolov5:
```bash
python detect.py \
  --img 640 \
  --weights ../runs_yolov5/lamb_activity_yolov5s/weights/best.pt \
  --source ../data/images \
  --save-txt \
  --save-conf \
  --project ../runs_yolov5 \
  --name lamb_activity_test
```
This creates YOLO-format prediction text files under:
```bash
../runs_yolov5/lamb_activity_test/labels/
```
We then convert these predictions into a CSV with columns:
```bash
frame_index,image_id,class_name,score,xmin,ymin,xmax,ymax
```
and save it to:
```bash
data/detections/sample_detections.csv
```
The small utility script that performs this conversion can be placed alongside our other tools (for example as src/detection/export_detections_template.py) and is described in the codebase.

5. Evaluate detection and run tracking

Once data/detections/sample_detections.csv is ready, we run from the repository root:
```bash
python -m src.detection.evaluate_detection
python -m src.tracking.track_from_detections
python -m src.analysis.behavior_stats
```
These commands:

Compute AP and mAP at IoU 0.5 against our VOC ground truth.

Produce data/detections/tracks.csv with tracked lamb trajectories.

Summarize behavior statistics (time spent per activity per lamb and overall).
